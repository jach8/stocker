{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "data = np.array(\n",
    "    [\n",
    "        [.885, .725, .560, .735, .610, .260, .5, .32],\n",
    "        [.33, .39, .5, .570, .63, .63, .68, .78], \n",
    "        [9.1, 10.9, 9.4, 9.8, 8.4, 11.8, 10.5, 10],\n",
    "        [4,5,6,5,3,8,7,6]\n",
    "    ]\n",
    ").T\n",
    "\n",
    "X = data[:,:-1]\n",
    "Y = data[:,-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithm (JR Quinlan)\n",
    "\n",
    "```python\n",
    "def build_tree(data)\n",
    "    if data.shape[0] == 1: \n",
    "        return [leaf, data.y, NA, NA] \n",
    "    if all data.y same: \n",
    "        return [leaf, data.y, NA, NA] \n",
    "    else\n",
    "        # determine best feature i to split on\n",
    "        SplitVal = data[:,i].median()\n",
    "        lefttree = build_tree(data[data[:,i]<=SplitVal]) \n",
    "        righttree = build_tree(data[data[:,i]>SplitVal]) \n",
    "        root = [i, SplitVal, 1, lefttree.shape[0] + 1] \n",
    "        return append(root, lefttree, righttree)\n",
    "```\n",
    "\n",
    "How to determine the \"best\" Feature? \n",
    "- Goal: Divide and Conquer\n",
    "- Group Data into most similar groups. \n",
    "\n",
    "Approaches: \n",
    "- Information Gain: Entropy\n",
    "- Information Gain: Correlation \n",
    "- Information Gain: Gini Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 3., 4., 3., 3., 3., 3., 3., 3.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DTLearner:\n",
    "    def __init__(self, leaf_size = 1, verbose = False):\n",
    "        self.leaf_size = leaf_size \n",
    "        self.verbose = verbose\n",
    "        self.tree = None\n",
    "\n",
    "\n",
    "    def author(self):\n",
    "        return 'jachaibar3'\n",
    "    \n",
    "    def add_evidence(self, data_x, data_y):\n",
    "        self.X = data_x\n",
    "        self.y = data_y\n",
    "        self.data = np.concatenate((data_x, data_y), axis = 1)\n",
    "\n",
    "    def feature_selection(self, data):\n",
    "        # Return the column index of the highest correlated feature. \n",
    "        # Transpose to get variables as rows. (see np.corcoef doc)\n",
    "        # [:-1, -1]: -1 gives the last col. in correl matrix, :-1 excludes corr of y and itself (1). \n",
    "        # argmax returns the column index of the max correlation \n",
    "        return np.abs(np.corrcoef(data.T))[:-1, -1].argmax().astype(int)\n",
    "\n",
    "    def build_tree(self, data):\n",
    "        if data.shape[0] <= self.leaf_size: \n",
    "            stop1 = np.array([['Leaf', data[:, -1][0], np.nan, np.nan]], dtype = object)\n",
    "            if self.verbose: \n",
    "                print(f'Stop Cond 1: Rows less than the leaf size: {data.shape}')\n",
    "            return stop1\n",
    "        if np.unique(data[:, -1]).shape[0] <= 1:\n",
    "            stop2 = np.array([['Leaf', data[:, -1][0], np.nan, np.nan]], dtype = object)\n",
    "            if self.verbose: \n",
    "                print(f'Stop Cond 2: All Y values are the same: {data.shape}, Y: {data[:, -1]}')\n",
    "            return stop2\n",
    "\n",
    "        else:\n",
    "            x_ind = self.feature_selection(data)\n",
    "            split_val = np.median(data[:, x_ind]).astype(float).round(3)\n",
    "            if self.verbose:\n",
    "                print(f'X vals: {data[:, x_ind][:5]} Split val: {split_val}')\n",
    "            left_tree = self.build_tree(data[data[:, x_ind] <= split_val])\n",
    "            right_tree = self.build_tree(data[data[:, x_ind] > split_val])\n",
    "            root = np.array([[x_ind, split_val, 1, left_tree.shape[0] + 1]])\n",
    "            self.tree = np.append(root, np.append(left_tree, right_tree, axis = 0), axis = 0)\n",
    "            return self.tree\n",
    "    \n",
    "    def query(self, points):\n",
    "        \"\"\"\n",
    "        Predict Y given the test set of X. \n",
    "        Given X (data points) evaluate the tree to return a leaf value for the prediction of Y. \n",
    "        \"\"\"  \n",
    "        for row in range(points.shape[0]):\n",
    "            i = 0\n",
    "            while self.tree[i, 0] != 'Leaf':\n",
    "                if points[row, int(self.tree[i, 0])] <= float(self.tree[i, 1]):\n",
    "                    i += int(self.tree[i, 2])\n",
    "                else:\n",
    "                    i += int(self.tree[i, 3])\n",
    "            points[row, -1] = self.tree[i, 1]\n",
    "        return points[:, -1]\n",
    "\n",
    "learn = DTLearner(leaf_size=1)\n",
    "learn.add_evidence(X, Y[:, np.newaxis])\n",
    "ar = learn.build_tree(data)\n",
    "# Test query\n",
    "X_test = np.random.uniform(-1,1, size=(10,3)) \n",
    "learn.query(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0, 9.9, 1.0, 8.0],\n",
       "       [2.0, 9.25, 1.0, 4.0],\n",
       "       [0.0, 0.748, 1.0, 2.0],\n",
       "       ['Leaf', 3.0, nan, nan],\n",
       "       ['Leaf', 4.0, nan, nan],\n",
       "       [0.0, 0.648, 1.0, 2.0],\n",
       "       ['Leaf', 6.0, nan, nan],\n",
       "       ['Leaf', 5.0, nan, nan],\n",
       "       [0.0, 0.41, 1.0, 4.0],\n",
       "       [1.0, 0.705, 1.0, 2.0],\n",
       "       ['Leaf', 8.0, nan, nan],\n",
       "       ['Leaf', 6.0, nan, nan],\n",
       "       [1.0, 0.535, 1.0, 2.0],\n",
       "       ['Leaf', 5.0, nan, nan],\n",
       "       ['Leaf', 7.0, nan, nan]], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Tree Algorithim (A Cutler)\n",
    "\n",
    "```python\n",
    "def build_tree(data):\n",
    "    if data.shape[0] == 1: \n",
    "        return [leaf, data.y, NA, NA] \n",
    "    if all data.y same: \n",
    "        return [leaf, data.y, NA, NA] \n",
    "    else\n",
    "        # determine random feature i to split on\n",
    "        SplitVal = (data[random,i] + data[random,i]) / 2 \n",
    "        lefttree = build_tree(data[data[:,i]<=SplitVal]) \n",
    "        righttree = build_tree(data[data[:,i]>SplitVal]) \n",
    "        root = [i, SplitVal, 1, lefttree.shape[0] + 1] \n",
    "        return (append(root, lefttree, righttree))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X vals: [0.33 0.39 0.5  0.57 0.63] Split val: 0.6\n",
      "X vals: [0.885 0.725 0.56  0.735] Split val: 0.73\n",
      "X vals: [10.9  9.4] Split val: 10.15\n",
      "Leaf found: (1, 4), Y: [6.]\n",
      "Leaf found: (1, 4), Y: [5.]\n",
      "X vals: [0.33 0.57] Split val: 0.45\n",
      "Leaf found: (1, 4), Y: [4.]\n",
      "Leaf found: (1, 4), Y: [5.]\n",
      "X vals: [ 8.4 11.8 10.5 10. ] Split val: 10.25\n",
      "X vals: [ 8.4 10. ] Split val: 9.2\n",
      "Leaf found: (1, 4), Y: [3.]\n",
      "Leaf found: (1, 4), Y: [6.]\n",
      "X vals: [0.63 0.68] Split val: 0.655\n",
      "Leaf found: (1, 4), Y: [8.]\n",
      "Leaf found: (1, 4), Y: [7.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3z/0n7lmcsd5h3969t725gndl740000gn/T/ipykernel_47361/3193013177.py:64: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  points[row, -1] = self.tree[i, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3., 4., 6.]), array([ 60,  38, 902]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RTLearner:\n",
    "    def __init__(self, leaf_size = 1, verbose = False):\n",
    "        self.leaf_size = leaf_size \n",
    "        self.verbose = verbose\n",
    "        self.tree = None # 0: feature ind, 1: split val, 2: left node, 3: right node\n",
    "\n",
    "\n",
    "    def author(self):\n",
    "        return 'jachaibar3'\n",
    "    \n",
    "    def add_evidence(self, data_x, data_y):\n",
    "        self.X = data_x\n",
    "        self.y = data_y\n",
    "        self.data = np.concatenate((data_x, data_y), axis = 1)\n",
    "\n",
    "    def feature_selection(self, data):\n",
    "        # Return random column index of the highest correlated feature. \n",
    "        return np.random.randint(0, data.shape[1] - 1)\n",
    "\n",
    "    def build_tree(self, data):\n",
    "        if data.shape[0] <= self.leaf_size: \n",
    "            stop1 = np.array([['Leaf', data[:, -1], np.nan, np.nan]], dtype = object)\n",
    "            if self.verbose: \n",
    "                print(f'Leaf found: {data.shape}, Y: {data[:, -1]}')\n",
    "            return stop1\n",
    "        if np.unique(data[:, -1]).shape[0] <= 1:\n",
    "            stop2 = np.array([['Leaf', data[:, -1][0], np.nan, np.nan]], dtype = object)\n",
    "            if self.verbose: \n",
    "                print(f'Leaf found: {data.shape}, Y: {data[:, -1]}')\n",
    "            return stop2\n",
    "\n",
    "        else:\n",
    "            x_ind = self.feature_selection(data)\n",
    "            split_val = np.median(data[:, x_ind]).astype(float).round(3)\n",
    "            if self.verbose: \n",
    "                print(f'X vals: {data[:, x_ind][:5]} Split val: {split_val}')\n",
    "            left_tree = self.build_tree(data[data[:, x_ind] <= split_val])\n",
    "            right_tree = self.build_tree(data[data[:, x_ind] > split_val])\n",
    "            root = np.array([[x_ind, split_val, 1, left_tree.shape[0] + 1]])\n",
    "            self.tree = np.append(root, np.append(left_tree, right_tree, axis = 0), axis = 0)\n",
    "            return self.tree\n",
    "    \n",
    "    def query(self, points):\n",
    "        \"\"\"\n",
    "        Predict Y given the test set of X. \n",
    "        Given X (data points) evaluate the tree to return a leaf value for the prediction of Y. \n",
    "        \"\"\"  \n",
    "        for row in range(points.shape[0]): # For each row in the test set\n",
    "            i = 0 # Start at the root \n",
    "    \n",
    "            while self.tree[i, 0] != 'Leaf': # While the current node is not a leaf\n",
    "\n",
    "                # Check the test value agianst the split value of the current node\n",
    "                if points[row, int(self.tree[i, 0])] <= float(self.tree[i, 1]): \n",
    "    \n",
    "                    # If the value is less, use the left node index\n",
    "                    i += int(self.tree[i, 2])\n",
    "                else:\n",
    "    \n",
    "                    # if the value is more use the right node index \n",
    "                    i += int(self.tree[i, 3])\n",
    "    \n",
    "            # Once the leaf is reached, assign the leaf value to the test set\n",
    "            points[row, -1] = self.tree[i, 1]\n",
    "        # return the leaf values for the test set \n",
    "        return points[:,-1]\n",
    "\n",
    "\n",
    "random_learner = RTLearner(leaf_size=1, verbose=True)\n",
    "random_learner.add_evidence(X, Y[:, np.newaxis])\n",
    "ar = random_learner.build_tree(data)\n",
    "\n",
    "# Test query\n",
    "X_test = np.random.normal(-1,1, size=(1000,4))\n",
    "np.unique(random_learner.query(X_test), return_counts=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strengths and weaknesses of decision tree learners\n",
    "• Cost of learning:\n",
    "- Most: Decision Trees\n",
    "- Medium: Linear Regression \n",
    "- Least: KNN\n",
    "\n",
    "• Cost of query: \n",
    "- Most: KNN\n",
    "- Medium: Decision Trees \n",
    "- Least: Linear Regression\n",
    "\n",
    "• Trees: Dont have to normalize your data and can easily handle missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options db Connected: 2024-07-23 20:26:26.065501\n",
      "Prices Connected: 2024-07-23 20:26:26.066470\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import sys\n",
    "sys.path.append(\"/Users/jerald/Documents/Dir/Python/Stocks\")\n",
    "\n",
    "from jetaa.sat.indicators import Indicators\n",
    "from bin.main import Manager \n",
    "\n",
    "M = Manager('../../')\n",
    "\n",
    "prices = M.Pricedb.ohlc('spy')\n",
    "G = Indicators(prices)\n",
    "df = G.get_states()['2023-01-01':]\n",
    "# df = df.resample('w').last()\n",
    "\n",
    "returns = pd.DataFrame({'returns_1d': df['Close'].pct_change(1),\n",
    "                        'returns_3d': df['Close'].pct_change(3),\n",
    "                        'returns_5d': df['Close'].pct_change(5),})\n",
    "\n",
    "# 1 = Buy, 0 = Hold, 2 = Sell \n",
    "multi_class = lambda x: 1 if x > 0.01 else 0 if x < -0.01 else 2\n",
    "# data = pandas.read_csv('Data/Istanbul.csv', index_col=0).reset_index(drop=True).to_numpy()\n",
    "# X = data[:,:-1]\n",
    "# Y = data[:,-1][:, np.newaxis]\n",
    "\n",
    "X = df.iloc[:, 1:].to_numpy()\n",
    "Y = returns.returns_1d.values[:, np.newaxis]\n",
    "learner = DTLearner(leaf_size=1, verbose=True)\n",
    "learner.add_evidence(X, Y)\n",
    "ar = learner.build_tree(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
